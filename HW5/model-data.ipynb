{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build Predictive Model(s)\n",
    "\n",
    "In this workbook, you will read the merged dataset you created previously and you will create pipelines to build a binary classification model to predict wether a trip has a tip or not.\n",
    "\n",
    "Instructions:\n",
    "\n",
    "1. Read in your merged dataset\n",
    "2. Use transformes and encoders to perform feature engineering\n",
    "3. Split into training and testing\n",
    "4. Build `LogisticRegression` model(s) and train them using pipelines\n",
    "5. Evaluate the performance of the model(s) using `BinaryClassificationMetrics`\n",
    "\n",
    "You are welcome to add as many cells as you need below up until the next section. **You must include comments in your code.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start SparkSession\n",
    "import findspark\n",
    "findspark.init()\n",
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.appName(\"HW-5\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://ip-172-31-32-158.ec2.internal:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v2.4.0</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>yarn</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>HW-5</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x7f13a6483710>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test whether the Spark can work\n",
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark import SparkContext, SparkConf\n",
    "sc    = spark.sparkContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://ip-172-31-32-158.ec2.internal:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v2.4.0</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>yarn</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>HW-5</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        "
      ],
      "text/plain": [
       "<SparkContext master=yarn appName=HW-5>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "from pyspark.sql.functions import UserDefinedFunction\n",
    "from pyspark.ml import Pipeline, Model\n",
    "from pyspark.ml.feature import OneHotEncoder, StringIndexer, VectorIndexer\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql import functions\n",
    "from pyspark.ml.classification import LogisticRegression\n",
    "from pyspark.mllib.evaluation import BinaryClassificationMetrics\n",
    "from pyspark.ml.feature import RFormula\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "nyctaxi = spark.read.parquet(\"s3://zzzzzzhy0607/merged_data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- medallion: string (nullable = true)\n",
      " |-- hack_license: string (nullable = true)\n",
      " |-- vendor_id: string (nullable = true)\n",
      " |-- pickup_datetime: timestamp (nullable = true)\n",
      " |-- payment_type: string (nullable = true)\n",
      " |-- fare_amount: float (nullable = true)\n",
      " |-- surcharge: float (nullable = true)\n",
      " |-- mta_tax: float (nullable = true)\n",
      " |-- tip_amount: float (nullable = true)\n",
      " |-- tolls_amount: float (nullable = true)\n",
      " |-- total_amount: float (nullable = true)\n",
      " |-- rate_code: integer (nullable = true)\n",
      " |-- store_and_fwd_flag: string (nullable = true)\n",
      " |-- dropoff_datetime: timestamp (nullable = true)\n",
      " |-- passenger_count: integer (nullable = true)\n",
      " |-- trip_time_in_secs: float (nullable = true)\n",
      " |-- trip_distance: float (nullable = true)\n",
      " |-- pickup_longitude: float (nullable = true)\n",
      " |-- pickup_latitude: float (nullable = true)\n",
      " |-- dropoff_longitude: float (nullable = true)\n",
      " |-- dropoff_latitude: float (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# See the data schema\n",
    "nyctaxi.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we want to build a binary classification model to predict whether a trip has a tip or not. We need to add a variable to indicate whether or not there was a tip. We created a column called `tipped`. It is 0 if the tip is 0, otherwise it is 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If tipped 1, otherwise 0\n",
    "nyctaxi=nyctaxi.withColumn(\"tipped\", when(nyctaxi[\"tip_amount\"]>0.0, 1).otherwise(0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also want to create other variables using `pickup_datetime`. Since the numerical time is not useful to interpret the results. We want to create the following variables:\n",
    "* `pickup_hour` from `pickup_datetime`, which indicates the hour of a day\n",
    "* `weekday` from `pickup_datetime`, which indicates the day of a week"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create other variables\n",
    "nyctaxi=nyctaxi.withColumn(\"pickup_hour\", hour(col(\"pickup_datetime\")))\n",
    "nyctaxi=nyctaxi.withColumn(\"weekday\", date_format(\"pickup_datetime\",'EEEE'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the variable `pickup_hour`, create a categorical variable to indicate whether the pick up time is in rush hour \n",
    "* If the value of the pickup hour is at-or-before 6am, or at-or-after 8pm, then the value is \"night\"\n",
    "* If the value of the pickup hour is between 7am and 10am (inclusive), then the value is \"am_rush\"\n",
    "* If the value of the pickup hour is between 11am and 3pm (inclusive), then the value is \"afternoon\"\n",
    "* If the value of the pickup hour is between 4pm and 7pm (inclusive), then the value is \"pm_rush\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "nyctaxi.createOrReplaceTempView(\"nyctaxi_table\")\n",
    "nyctaxi = spark.sql(\"\"\"SELECT *,\n",
    "CASE WHEN pickup_hour <= 6 OR pickup_hour >= 20 THEN 'night'\n",
    "     WHEN pickup_hour >= 7 AND pickup_hour <= 10 THEN 'am_rush'\n",
    "     WHEN pickup_hour >= 11 AND pickup_hour <= 15 THEN 'afternoon'\n",
    "     ELSE 'pm_rush' END AS time_bins\n",
    "FROM nyctaxi_table\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- medallion: string (nullable = true)\n",
      " |-- hack_license: string (nullable = true)\n",
      " |-- vendor_id: string (nullable = true)\n",
      " |-- pickup_datetime: timestamp (nullable = true)\n",
      " |-- payment_type: string (nullable = true)\n",
      " |-- fare_amount: float (nullable = true)\n",
      " |-- surcharge: float (nullable = true)\n",
      " |-- mta_tax: float (nullable = true)\n",
      " |-- tip_amount: float (nullable = true)\n",
      " |-- tolls_amount: float (nullable = true)\n",
      " |-- total_amount: float (nullable = true)\n",
      " |-- rate_code: integer (nullable = true)\n",
      " |-- store_and_fwd_flag: string (nullable = true)\n",
      " |-- dropoff_datetime: timestamp (nullable = true)\n",
      " |-- passenger_count: integer (nullable = true)\n",
      " |-- trip_time_in_secs: float (nullable = true)\n",
      " |-- trip_distance: float (nullable = true)\n",
      " |-- pickup_longitude: float (nullable = true)\n",
      " |-- pickup_latitude: float (nullable = true)\n",
      " |-- dropoff_longitude: float (nullable = true)\n",
      " |-- dropoff_latitude: float (nullable = true)\n",
      " |-- tipped: integer (nullable = false)\n",
      " |-- pickup_hour: integer (nullable = true)\n",
      " |-- weekday: string (nullable = true)\n",
      " |-- time_bins: string (nullable = false)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Check the schema now\n",
    "nyctaxi.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To build the predictive model, we need to convert all the string fields to numeric ones \n",
    "# Use the StringIndexer transformer\n",
    "# take data in, and produce new data\n",
    "string_vendor = StringIndexer(inputCol=\"vendor_id\", outputCol=\"vendor_X\")\n",
    "string_rate = StringIndexer(inputCol=\"rate_code\", outputCol=\"rate_X\")\n",
    "string_payment = StringIndexer(inputCol=\"payment_type\", outputCol=\"payment_X\")\n",
    "string_time = StringIndexer(inputCol=\"time_bins\", outputCol=\"time_bins_X\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use OneHotEncoder \n",
    "# Take data in and produce a transformer\n",
    "# Convert the index to a vector of dummy variables.\n",
    "encoder_vendor = OneHotEncoder(inputCol=\"vendor_X\", outputCol=\"vendor_vec\", dropLast=False)\n",
    "encoder_rate = OneHotEncoder(inputCol=\"rate_X\", outputCol=\"rate_vec\", dropLast=False)\n",
    "encoder_payment = OneHotEncoder(inputCol=\"payment_X\", outputCol=\"payment_vec\", dropLast=False)\n",
    "encoder_time = OneHotEncoder(inputCol=\"time_bins_X\", outputCol=\"time_bins_vec\", dropLast=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build a pipeline called nyc_final\n",
    "# Run a fit method and a transform method to get the desired results.\n",
    "nyc_final = Pipeline(stages=[string_vendor, encoder_vendor, string_rate, encoder_rate, \n",
    "                             string_payment, encoder_payment, string_time, encoder_time\n",
    "                            ]).fit(nyctaxi).transform(nyctaxi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+---------+-------------------+------------+-----------+---------+-------+----------+------------+------------+---------+------------------+-------------------+---------------+-----------------+-------------+----------------+---------------+-----------------+----------------+------+-----------+---------+---------+--------+-------------+------+--------------+---------+-------------+-----------+-------------+\n",
      "|           medallion|        hack_license|vendor_id|    pickup_datetime|payment_type|fare_amount|surcharge|mta_tax|tip_amount|tolls_amount|total_amount|rate_code|store_and_fwd_flag|   dropoff_datetime|passenger_count|trip_time_in_secs|trip_distance|pickup_longitude|pickup_latitude|dropoff_longitude|dropoff_latitude|tipped|pickup_hour|  weekday|time_bins|vendor_X|   vendor_vec|rate_X|      rate_vec|payment_X|  payment_vec|time_bins_X|time_bins_vec|\n",
      "+--------------------+--------------------+---------+-------------------+------------+-----------+---------+-------+----------+------------+------------+---------+------------------+-------------------+---------------+-----------------+-------------+----------------+---------------+-----------------+----------------+------+-----------+---------+---------+--------+-------------+------+--------------+---------+-------------+-----------+-------------+\n",
      "|00005007A9F30E289...|132A7AC13C8471488...|      CMT|2013-07-30 22:50:31|         CRD|       10.5|      0.5|    0.5|       3.0|         0.0|        14.5|        1|                 N|2013-07-30 23:01:50|              1|            679.0|          2.5|       -73.98164|      40.752388|        -73.98296|        40.77576|     1|         22|  Tuesday|    night|     0.0|(2,[0],[1.0])|   0.0|(26,[0],[1.0])|      0.0|(5,[0],[1.0])|        0.0|(4,[0],[1.0])|\n",
      "|00005007A9F30E289...|16780B3E72BAA7A5C...|      CMT|2013-07-16 19:22:49|         CSH|        2.5|      1.0|    0.5|       0.0|         0.0|         4.0|        1|                 N|2013-07-16 19:40:47|              1|           1078.0|          0.0|       -73.98587|        40.7599|        -73.98545|       40.747894|     0|         19|  Tuesday|  pm_rush|     0.0|(2,[0],[1.0])|   0.0|(26,[0],[1.0])|      1.0|(5,[1],[1.0])|        2.0|(4,[2],[1.0])|\n",
      "|00005007A9F30E289...|24C122A944FB8EE21...|      CMT|2013-10-11 11:18:25|         CRD|        5.5|      0.0|    0.5|       1.0|         0.0|         7.0|        1|                 Y|2013-10-11 11:23:11|              1|            285.0|          0.9|         -73.997|       40.72245|       -73.986115|        40.72926|     1|         11|   Friday|afternoon|     0.0|(2,[0],[1.0])|   0.0|(26,[0],[1.0])|      0.0|(5,[0],[1.0])|        1.0|(4,[1],[1.0])|\n",
      "|00005007A9F30E289...|24C122A944FB8EE21...|      CMT|2013-10-21 07:45:29|         CRD|        7.5|      0.0|    0.5|       1.1|         0.0|         9.1|        1|                 N|2013-10-21 07:52:41|              1|            432.0|          1.7|      -73.958084|      40.778934|        -73.97548|       40.760258|     1|          7|   Monday|  am_rush|     0.0|(2,[0],[1.0])|   0.0|(26,[0],[1.0])|      0.0|(5,[0],[1.0])|        3.0|(4,[3],[1.0])|\n",
      "|00005007A9F30E289...|24C122A944FB8EE21...|      CMT|2013-10-21 16:23:04|         CSH|        5.5|      1.0|    0.5|       0.0|         0.0|         7.0|        1|                 N|2013-10-21 16:28:01|              3|            297.0|          0.9|       -73.97213|      40.793816|        -73.96275|        40.80438|     0|         16|   Monday|  pm_rush|     0.0|(2,[0],[1.0])|   0.0|(26,[0],[1.0])|      1.0|(5,[1],[1.0])|        2.0|(4,[2],[1.0])|\n",
      "|00005007A9F30E289...|24C122A944FB8EE21...|      CMT|2013-10-23 06:40:22|         CRD|       10.0|      0.0|    0.5|       2.1|         0.0|        12.6|        1|                 N|2013-10-23 06:48:34|              1|            491.0|          2.8|       -73.97342|       40.78475|        -73.98238|       40.755123|     1|          6|Wednesday|    night|     0.0|(2,[0],[1.0])|   0.0|(26,[0],[1.0])|      0.0|(5,[0],[1.0])|        0.0|(4,[0],[1.0])|\n",
      "|00005007A9F30E289...|24C122A944FB8EE21...|      CMT|2013-10-30 09:52:19|         CRD|        6.0|      0.0|    0.5|       1.3|         0.0|         7.8|        1|                 N|2013-10-30 09:59:08|              1|            409.0|          0.7|       -73.98036|       40.75155|        -73.98551|       40.743267|     1|          9|Wednesday|  am_rush|     0.0|(2,[0],[1.0])|   0.0|(26,[0],[1.0])|      0.0|(5,[0],[1.0])|        3.0|(4,[3],[1.0])|\n",
      "|00005007A9F30E289...|24C122A944FB8EE21...|      CMT|2013-10-30 14:32:32|         CSH|        7.5|      0.0|    0.5|       0.0|         0.0|         8.0|        1|                 N|2013-10-30 14:41:54|              1|            561.0|          0.9|       -73.98616|      40.755646|        -73.96923|       40.761013|     0|         14|Wednesday|afternoon|     0.0|(2,[0],[1.0])|   0.0|(26,[0],[1.0])|      1.0|(5,[1],[1.0])|        1.0|(4,[1],[1.0])|\n",
      "|00005007A9F30E289...|24C122A944FB8EE21...|      CMT|2013-11-07 07:40:09|         CSH|        2.5|      0.0|    0.5|       0.0|         0.0|         3.0|        1|                 N|2013-11-07 07:45:16|              1|            307.0|          0.0|       -73.95689|       40.77837|        -73.97008|        40.76448|     0|          7| Thursday|  am_rush|     0.0|(2,[0],[1.0])|   0.0|(26,[0],[1.0])|      1.0|(5,[1],[1.0])|        3.0|(4,[3],[1.0])|\n",
      "|00005007A9F30E289...|24C122A944FB8EE21...|      CMT|2013-11-07 10:26:14|         CRD|        8.0|      0.0|    0.5|       1.0|         0.0|         9.5|        1|                 N|2013-11-07 10:37:14|              1|            660.0|          1.0|       -74.00441|      40.752228|        -73.99227|        40.75503|     1|         10| Thursday|  am_rush|     0.0|(2,[0],[1.0])|   0.0|(26,[0],[1.0])|      0.0|(5,[0],[1.0])|        3.0|(4,[3],[1.0])|\n",
      "+--------------------+--------------------+---------+-------------------+------------+-----------+---------+-------+----------+------------+------------+---------+------------------+-------------------+---------------+-----------------+-------------+----------------+---------------+-----------------+----------------+------+-----------+---------+---------+--------+-------------+------+--------------+---------+-------------+-----------+-------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Show the first 10 rows of the final datatset\n",
    "nyc_final.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training records: 138553296\n",
      "Number of testing records : 34631795\n"
     ]
    }
   ],
   "source": [
    "# Split into training and testing\n",
    "splitted_data = nyc_final.randomSplit([0.8, 0.2], 24)\n",
    "train_data = splitted_data[0]\n",
    "test_data = splitted_data[1]\n",
    "\n",
    "print(\"Number of training records: \" + str(train_data.count()))\n",
    "print(\"Number of testing records : \" + str(test_data.count()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[medallion: string, hack_license: string, vendor_id: string, pickup_datetime: timestamp, payment_type: string, fare_amount: float, surcharge: float, mta_tax: float, tip_amount: float, tolls_amount: float, total_amount: float, rate_code: int, store_and_fwd_flag: string, dropoff_datetime: timestamp, passenger_count: int, trip_time_in_secs: float, trip_distance: float, pickup_longitude: float, pickup_latitude: float, dropoff_longitude: float, dropoff_latitude: float, tipped: int, pickup_hour: int, weekday: string, time_bins: string, vendor_X: double, vendor_vec: vector, rate_X: double, rate_vec: vector, payment_X: double, payment_vec: vector, time_bins_X: double, time_bins_vec: vector]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cache the two datasets\n",
    "train_data.cache()\n",
    "test_data.cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build LogisticRegression model\n",
    "log_reg = LogisticRegression(maxIter=10, regParam=0.3, elasticNetParam=0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using Pickup_hour, Passenger count, Trip time, Trip distance\n",
    "# Fare amount, Vendor id, Payment type, Rate code, Time bins\n",
    "class_formula = RFormula(formula=\"tipped ~ pickup_hour + passenger_count + trip_time_in_secs + trip_distance + fare_amount + vendor_X + rate_X + payment_X + time_bins_X\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build model using pipline\n",
    "model = Pipeline(stages=[class_formula, log_reg]).fit(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions on the test dataset\n",
    "predictions = model.transform(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the prediction results into rdd\n",
    "predictions_and_labels = predictions['label', 'prediction'].rdd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build metrics on the rdd \n",
    "metrics = BinaryClassificationMetrics(predictions_and_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## In the following cells, please provide the requested code and output. Do not change the order and/or structure of the cells."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the following cell, print the Area Under the Curve (AUC) for your binary classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Area under ROC = 0.9832633696283052\n"
     ]
    }
   ],
   "source": [
    "print(\"Area under ROC = %s\" % metrics.areaUnderROC)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the following cell, provide the code that saves your model your S3 bucket."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model to S3\n",
    "model.save(\"s3://zzzzzzhy0607/hw5_model/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.stop()"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
